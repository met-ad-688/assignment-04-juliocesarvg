[
  {
    "objectID": "assignment04-juliocesarvg_sol.html",
    "href": "assignment04-juliocesarvg_sol.html",
    "title": "Assignment 04",
    "section": "",
    "text": "WARNING: Using incubator modules: jdk.incubator.vector\nUsing Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/10/09 02:57:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n25/10/09 02:57:39 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n                                                                                \n\n\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\nonly showing top 5 rows\n\n\n[Stage 3:&gt;                                                          (0 + 1) / 1]\n\n\n72498"
  },
  {
    "objectID": "assignment04-juliocesarvg_sol.html#chose-data-2.1",
    "href": "assignment04-juliocesarvg_sol.html#chose-data-2.1",
    "title": "Assignment 04",
    "section": "2.1 Chose Data (2.1)",
    "text": "2.1 Chose Data (2.1)"
  },
  {
    "objectID": "assignment04-juliocesarvg_sol.html#missing-value-treatment-2.2",
    "href": "assignment04-juliocesarvg_sol.html#missing-value-treatment-2.2",
    "title": "Assignment 04",
    "section": "2.2 Missing Value Treatment (2.2)",
    "text": "2.2 Missing Value Treatment (2.2)\n\n\n                                                                                \n\n\n\n2.2.1 Drop rows with missing values (2.2.1)"
  },
  {
    "objectID": "assignment04-juliocesarvg_sol.html#convert-assemble-split-pipeline-2.3---2.6",
    "href": "assignment04-juliocesarvg_sol.html#convert-assemble-split-pipeline-2.3---2.6",
    "title": "Assignment 04",
    "section": "2.3 Convert, Assemble, Split, Pipeline (2.3 - 2.6)",
    "text": "2.3 Convert, Assemble, Split, Pipeline (2.3 - 2.6)\n\nConvert categorical variables into numerical representations using StringIndexer and OneHotEncoder.\nAssemble features into a single vector using VectorAssembler.\nSplit the data into training and testing sets.\nYou can use pipeline to do the above steps in one go.\n\n\n\n                                                                                \n\n\n(23697, 12)\n\n\n                                                                                \n\n\n(18966, 12)\n\n\n                                                                                \n\n\n(4731, 12)\n+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\n|SALARY|MIN_YEARS_EXPERIENCE|DURATION|IS_INTERNSHIP|COMPANY_IS_STAFFING|REMOTE_TYPE_NAME|EMPLOYMENT_TYPE_NAME|EMPLOYMENT_TYPE_NAME_idx|REMOTE_TYPE_NAME_idx|EMPLOYMENT_TYPE_NAME_vec|REMOTE_TYPE_NAME_vec|features                       |\n+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\n|92962 |2                   |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[2.0,18.0,1.0,0.0,1.0,0.0,0.0] |\n|107645|10                  |18      |0            |0                  |On-Premise      |Fulltime            |0.0                     |3.0                 |(2,[0],[1.0])           |(3,[],[])           |(7,[0,1,2],[10.0,18.0,1.0])    |\n|192800|6                   |55      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[6.0,55.0,1.0,0.0,1.0,0.0,0.0] |\n|125900|12                  |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[12.0,18.0,1.0,0.0,1.0,0.0,0.0]|\n|170000|6                   |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[6.0,18.0,1.0,0.0,1.0,0.0,0.0] |\n+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\nonly showing top 5 rows\n\n\n\nCreate a new column MIN_YEARS_EXPERIENCE_SQ by squaring the MIN_YEARS_EXPERIENCE column.\nAssemble the polynomial features into a new vector column features_poly using VectorAssembler.\nShow the final structure of the DataFrame with the new features.\n\n\n\n+------+-------------------------------+------------------------------------------+\n|SALARY|features                       |features_poly                             |\n+------+-------------------------------+------------------------------------------+\n|92962 |[2.0,18.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[2.0,4.0,18.0,1.0,1.0])   |\n|107645|(7,[0,1,2],[10.0,18.0,1.0])    |(10,[0,1,2,5],[10.0,100.0,18.0,1.0])      |\n|192800|[6.0,55.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[6.0,36.0,55.0,1.0,1.0])  |\n|125900|[12.0,18.0,1.0,0.0,1.0,0.0,0.0]|(10,[0,1,2,5,7],[12.0,144.0,18.0,1.0,1.0])|\n|170000|[6.0,18.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[6.0,36.0,18.0,1.0,1.0])  |\n+------+-------------------------------+------------------------------------------+\nonly showing top 5 rows"
  },
  {
    "objectID": "assignment04-juliocesarvg_sol.html#generalized-linear-regression-summary",
    "href": "assignment04-juliocesarvg_sol.html#generalized-linear-regression-summary",
    "title": "Assignment 04",
    "section": "4.1 4.1 Generalized Linear Regression Summary",
    "text": "4.1 4.1 Generalized Linear Regression Summary\n\n\n                                                                                \n\n\nIntercept: 75142.6520\nCoefficients:\n Feature 1: 6629.0352\n Feature 2: -89.0893\n Feature 3: 758.1210\n Feature 4: -6686.4509\n Feature 5: 10858.3452\n Feature 6: 13681.8588\n Feature 7: 18835.8525\n\n--- Regression Summary ---\n\n\n                                                                                \n\n\nCoefficient Standard Errors: ['81.3631', '23.5386', '2051.7917', '2611.3277', '2048.9189', '2105.9892', '2544.8043', '2786.7053']\nT Values: ['81.4747', '-3.7848', '0.3695', '-2.5606', '5.2995', '6.4966', '7.4017', '26.9647']\nP Values: ['0.0000', '0.0002', '0.7118', '0.0105', '0.0000', '0.0000', '0.0000', '0.0000']\n\n\n                                                                                \n\n\nNull Deviance: 35794690345776.1094\nResidual DF Null: 18965\nDeviance: 26380276237620.0078\nResidual DF: 18958\n\n\n[Stage 49:&gt;                                                         (0 + 1) / 1]\n\n\nAIC: 453136.8230\n\n\n                                                                                \n\n\n\n\n\n\nFeature\nEstimate\nStd Error\nt-stat\np-Value\n\n\n\n\n0\nIntercept\n75142.6520\n81.3631\n81.4747\n0.0000\n\n\n1\nMIN_YEARS_EXPERIENCE\n6629.0352\n23.5386\n-3.7848\n0.0002\n\n\n2\nDURATION\n-89.0893\n2051.7917\n0.3695\n0.7118\n\n\n3\nEMPLOYMENT_TYPE_NAME_vec_Fulltime\n758.1210\n2611.3277\n-2.5606\n0.0105\n\n\n4\nEMPLOYMENT_TYPE_NAME_vec_Parttime\n-6686.4509\n2048.9189\n5.2995\n0.0000\n\n\n5\nREMOTE_TYPE_NAME_vec_Undefined\n10858.3452\n2105.9892\n6.4966\n0.0000\n\n\n6\nREMOTE_TYPE_NAME_vec_Remote\n13681.8588\n2544.8043\n7.4017\n0.0000\n\n\n7\nREMOTE_TYPE_NAME_vec_Hybrid\n18835.8525\n2786.7053\n26.9647\n0.0000"
  },
  {
    "objectID": "assignment04-juliocesarvg_sol.html#feature-importance-plot-6.1",
    "href": "assignment04-juliocesarvg_sol.html#feature-importance-plot-6.1",
    "title": "Assignment 04",
    "section": "6.1 Feature Importance Plot 6.1",
    "text": "6.1 Feature Importance Plot 6.1\n\nExtract the feature importance from the Random Forest model and plot them using Seaborn.\nUse a bar plot to visualize the top 10 most important features.\nSave the plot as rf_feature_importance.png in the _output/ folder.\n\n\n\n[0.87986289 0.06420253 0.01016472 0.00886554 0.01079688 0.01421165\n 0.01189578]\n['MIN_YEARS_EXPERIENCE', 'DURATION', 'EMPLOYMENT_TYPE_NAME_vec_Fulltime', 'EMPLOYMENT_TYPE_NAME_vec_Parttime', 'REMOTE_TYPE_NAME_vec_Undefined', 'REMOTE_TYPE_NAME_vec_Remote', 'REMOTE_TYPE_NAME_vec_Hybrid']\n['MIN_YEARS_EXPERIENCE', 'DURATION', 'EMPLOYMENT_TYPE_NAME_vec', 'REMOTE_TYPE_NAME_vec']"
  },
  {
    "objectID": "assignment04-juliocesarvg_sol.html#comments-7.1",
    "href": "assignment04-juliocesarvg_sol.html#comments-7.1",
    "title": "Assignment 04",
    "section": "7.1 Comments (7.1)",
    "text": "7.1 Comments (7.1)\n\nThe Random Forest model has the lowest RMSE, so it predicts better than the other two models.\nAll models show that when the real salary goes up, the predicted one also goes up.\nSome strange points may happen because the models are not perfect and have small inaccuracies, or because some factors that affect salary are not in the data."
  },
  {
    "objectID": "assignment04-juliocesarvg_sol.html#calculating-log-likelihood-and-bic-for-pyspark-models-7.2",
    "href": "assignment04-juliocesarvg_sol.html#calculating-log-likelihood-and-bic-for-pyspark-models-7.2",
    "title": "Assignment 04",
    "section": "7.2 Calculating Log-Likelihood and BIC for PySpark Models (7.2)",
    "text": "7.2 Calculating Log-Likelihood and BIC for PySpark Models (7.2)\nLog Likelihood represents the probability of observing the data given the model parameters. It is used in AIC and BIC calculations. Log Likelihood is not directly available in PySparkâ€™s GeneralizedLinearRegression model summary. However, you can calculate it using the deviance and the number of observations.\n\n\nGLR -&gt; Log-Likelihood: -226559.41,  BIC: 453197.63\nPolynomial GLR -&gt; Log-Likelihood: -226314.10,  BIC: 452736.56"
  },
  {
    "objectID": "assignment04-juliocesarvg_sol.html#comments",
    "href": "assignment04-juliocesarvg_sol.html#comments",
    "title": "Assignment 04",
    "section": "7.3 Comments",
    "text": "7.3 Comments\n\nThe Polynomial GLR fits the data slightly better since it has a lower BIC value but both models perform almost equally well.\nOverall, both GLR models provide a good fitbut the Polynomial GLR show a slightly better performance based on its lower BIC value."
  },
  {
    "objectID": "assignment04-juliocesarvg.html",
    "href": "assignment04-juliocesarvg.html",
    "title": "Assignment 04",
    "section": "",
    "text": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nimport numpy as np\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n\nnp.random.seed(42)\n\npio.renderers.default = \"notebook+notebook_connected+vscode\"\n\n# Initialize Spark Session\nspark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n\n# Load Data\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"data/lightcast_job_postings.csv\")\n\n# df.printSchema() # comment this line when rendering the submission\ndf.show(5)\nprint(df.count())\n\nWARNING: Using incubator modules: jdk.incubator.vector\nUsing Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/10/09 04:44:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n25/10/09 04:44:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n[Stage 1:&gt;                                                          (0 + 1) / 1]                                                                                25/10/09 04:45:12 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 2:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\nonly showing top 5 rows\n\n\n[Stage 3:&gt;                                                          (0 + 1) / 1]\n\n\n72498"
  },
  {
    "objectID": "assignment04-juliocesarvg.html#chose-data-2.1",
    "href": "assignment04-juliocesarvg.html#chose-data-2.1",
    "title": "Assignment 04",
    "section": "2.1 Chose Data (2.1)",
    "text": "2.1 Chose Data (2.1)\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n## Chose Categorial Columns and continuous \n# Dependent (y): SALARY\n# Independent  (X):\n# Four numerical/boolean features:\n#   MIN_YEARS_EXPERIENCE, DURATION, IS_INTERNSHIP, COMPANY_IS_STAFFING\n# Two categorical features:\n#   REMOTE_TYPE_NAME, EMPLOYMENT_TYPE_NAME\n\n\neda_cols = [\n    \"SALARY\",\n    \"MIN_YEARS_EXPERIENCE\", \"DURATION\",\n    \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\",\n    \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\"\n]\n\ndf_eda = df.select(eda_cols)"
  },
  {
    "objectID": "assignment04-juliocesarvg.html#missing-value-treatment-2.2",
    "href": "assignment04-juliocesarvg.html#missing-value-treatment-2.2",
    "title": "Assignment 04",
    "section": "2.2 Missing Value Treatment (2.2)",
    "text": "2.2 Missing Value Treatment (2.2)\n\nfrom pyspark.sql.functions import col, when, isnan, count\nfrom pyspark.sql import Window\nfrom pyspark.sql.functions import col, when, isnan, count, expr, median\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n#Cleaning - two categorical features\n\ndf_eda = df_eda.withColumn(\n    \"REMOTE_TYPE_NAME\",\n    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"Undefined\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On-Premise\")\n    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On-Premise\")\n    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n)\n\ndf_eda = df_eda.withColumn(\n    \"EMPLOYMENT_TYPE_NAME\",\n    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (Ã¢â€°Â¤ 32 hours)\", \"Parttime\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (&gt; 32 hours)\", \"Fulltime\")\n    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Fulltime\")\n    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n)\n\n#Cleaning Booleans -  IS_INTERNSHIP, COMPANY_IS_STAFFING\ndf_eda = df_eda.withColumn(\"IS_INTERNSHIP\", when(col(\"IS_INTERNSHIP\").isNull(), False).otherwise(col(\"IS_INTERNSHIP\")))\n\ndf_eda = df_eda.withColumn( \"COMPANY_IS_STAFFING\",when(col(\"COMPANY_IS_STAFFING\").isNull(), False).otherwise(col(\"COMPANY_IS_STAFFING\")) )\n\n#Cleaning Numericals with median in nulls - DURATION\n\nmedian_duration = df_eda.approxQuantile(\"DURATION\", [0.5], 0.01)[0]\n\ndf_eda = df_eda.withColumn(\"DURATION\",\n                            when(col(\"DURATION\").isNull(), median_duration)\n                            .otherwise(col(\"DURATION\"))\n                        )\n\n#Cleaning Dependent (y) with median by : SALARY\n\n#overall median\noverall_median_salary = df_eda.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\n\n# median by EMPLOYMENT_TYPE_NAME\nmedian_by_employment_type_name = df_eda.groupBy(\"EMPLOYMENT_TYPE_NAME\").agg(\n    expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type_name\")\n)\n\n# Join median values back to the original dataframe\ndf_salary_imputed = df_eda.join(median_by_employment_type_name, on=\"EMPLOYMENT_TYPE_NAME\", how=\"left\")\n\n# Replace missing SALARY values\ndf_eda_clean = df_salary_imputed.withColumn(\"SALARY\", when(col(\"SALARY\").isNull(),\n    when(col(\"median_salary_emp_type_name\").isNotNull(), col(\"median_salary_emp_type_name\"))\n    .otherwise(overall_median_salary)\n).otherwise(col(\"SALARY\")))\n\n# Verifying in Excel\n#df_eda_clean_pd = df_eda_clean.toPandas()\n#df_eda_clean_pd.to_excel(\"df_eda_clean.xlsx\", index=False, engine=\"openpyxl\")\n\n[Stage 8:&gt;                                                          (0 + 1) / 1]                                                                                [Stage 9:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n\n2.2.1 Drop rows with missing values (2.2.1)\n\n# Drop rows with NA values in relevant columns\n# eda_cols = [\n#     \"SALARY\",\n#     \"MIN_YEARS_EXPERIENCE\", \"DURATION\",\n#     \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\",\n#     \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\"\n# ]\nfrom pyspark.sql.types import BooleanType, StringType, IntegerType\nfrom pyspark.sql.types import IntegerType,DoubleType,DecimalType\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\n\nimport pandas as pd\nimport hvplot.pandas \n\n\n# NULLS BEFORE\ndf_before_pd = df.select(eda_cols).limit(2000).toPandas()\nmissing_before = df_before_pd.isnull().reset_index().melt(id_vars='index', var_name='column', value_name='is_missing')\nmissing_before[\"is_missing\"] = missing_before[\"is_missing\"].astype(int)\nheat_before = missing_before.hvplot.heatmap(\n    x=\"column\", y=\"index\", C=\"is_missing\",\n    cmap=\"Reds\", colorbar=False,\n    width=900, height=700,\n    title=\"Missing Values BEFORE cleaning\"\n).opts(xrotation=45)\n# NULLS AFTER\ndf_after_pd = df_eda_clean.select(eda_cols).limit(2000).toPandas()\nmissing_after = df_after_pd.isnull().reset_index().melt(id_vars='index', var_name='column', value_name='is_missing')\nmissing_after[\"is_missing\"] = missing_after[\"is_missing\"].astype(int)\nheat_after =missing_after.hvplot.heatmap(\n    x=\"column\", y=\"index\", C=\"is_missing\",\n    cmap=\"Reds\", colorbar=False,\n    width=900, height=700,\n    title=\"Missing Values AFTER cleaning\"\n).opts(xrotation=45)\ndisplay(heat_before)\ndisplay(heat_after)\n\n\n\n\n\nspark = (\n    SparkSession.builder\n    .appName(\"AD688-A5\")\n    .config(\"spark.ui.showConsoleProgress\", \"false\")\n    .getOrCreate()\n)\n\n\nregression_df = df_eda.dropna(subset=eda_cols)\n\n#Convert categorical/boolean columns to numeric types to avoid errors in Assembler, pipeline ...\nregression_df=regression_df.withColumn(\"IS_INTERNSHIP\", col(\"IS_INTERNSHIP\").cast(IntegerType()))\nregression_df=regression_df.withColumn(\"COMPANY_IS_STAFFING\", col(\"COMPANY_IS_STAFFING\").cast(IntegerType()))\nregression_df = regression_df.withColumn(\"DURATION\", col(\"DURATION\").cast(IntegerType()))\n\n# Verifying in Excel\n# regression_df = regression_df.toPandas()\n# regression_df.to_excel(\"df_eda_clean.xlsx\", index=False, engine=\"openpyxl\")\n\n#regression_df.schema\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n[Stage 11:&gt;                 (0 + 1) / 1][Stage 12:&gt;                 (0 + 1) / 1][Stage 12:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n25/10/09 04:46:04 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect."
  },
  {
    "objectID": "assignment04-juliocesarvg.html#convert-assemble-split-pipeline-2.3---2.6",
    "href": "assignment04-juliocesarvg.html#convert-assemble-split-pipeline-2.3---2.6",
    "title": "Assignment 04",
    "section": "2.3 Convert, Assemble, Split, Pipeline (2.3 - 2.6)",
    "text": "2.3 Convert, Assemble, Split, Pipeline (2.3 - 2.6)\n\nConvert categorical variables into numerical representations using StringIndexer and OneHotEncoder.\nAssemble features into a single vector using VectorAssembler.\nSplit the data into training and testing sets.\nYou can use pipeline to do the above steps in one go.\n\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\nfrom pyspark.ml import Pipeline\n\n\n# 2.3 to 2.6 Convert, Assemble, Split, Pipeline\n# Categorical columns\ncategorical_cols = [\"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\"]\n\n# Index and One-Hot Encode\nindexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid='skip') for col in categorical_cols]\nencoders = [OneHotEncoder(inputCol=f\"{col}_idx\", outputCol=f\"{col}_vec\") for col in categorical_cols]\n\n# Assemble base features\nassembler = VectorAssembler(\n    inputCols=[\n        \"MIN_YEARS_EXPERIENCE\", \"DURATION\"\n    ] + [f\"{col}_vec\" for col in categorical_cols],\n    outputCol=\"features\"\n)\n\n# Create Pipeline\npipeline = Pipeline(stages=indexers + encoders + [assembler])\nregression_data = pipeline.fit(regression_df).transform(regression_df)\n\n\n# Split Data\nregression_train, regression_test = regression_data.randomSplit([0.8, 0.2], seed=42)\nprint((regression_data.count(), len(regression_data.columns)))\nprint((regression_train.count(), len(regression_train.columns)))\nprint((regression_test.count(), len(regression_test.columns)))\n\nregression_data.show(5, truncate=False)\n\n[Stage 17:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 23:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 29:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\n(23697, 12)\n\n\n[Stage 32:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\n(18966, 12)\n\n\n[Stage 35:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\n(4731, 12)\n+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\n|SALARY|MIN_YEARS_EXPERIENCE|DURATION|IS_INTERNSHIP|COMPANY_IS_STAFFING|REMOTE_TYPE_NAME|EMPLOYMENT_TYPE_NAME|EMPLOYMENT_TYPE_NAME_idx|REMOTE_TYPE_NAME_idx|EMPLOYMENT_TYPE_NAME_vec|REMOTE_TYPE_NAME_vec|features                       |\n+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\n|92962 |2                   |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[2.0,18.0,1.0,0.0,1.0,0.0,0.0] |\n|107645|10                  |18      |0            |0                  |On-Premise      |Fulltime            |0.0                     |3.0                 |(2,[0],[1.0])           |(3,[],[])           |(7,[0,1,2],[10.0,18.0,1.0])    |\n|192800|6                   |55      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[6.0,55.0,1.0,0.0,1.0,0.0,0.0] |\n|125900|12                  |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[12.0,18.0,1.0,0.0,1.0,0.0,0.0]|\n|170000|6                   |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[6.0,18.0,1.0,0.0,1.0,0.0,0.0] |\n+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\nonly showing top 5 rows\n\n\n\nCreate a new column MIN_YEARS_EXPERIENCE_SQ by squaring the MIN_YEARS_EXPERIENCE column.\nAssemble the polynomial features into a new vector column features_poly using VectorAssembler.\nShow the final structure of the DataFrame with the new features.\n\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\nfrom pyspark.ml import Pipeline\n# Create squared term for Polynomial Regression\nregression_data_poly = regression_data.withColumn(\"MIN_YEARS_EXPERIENCE_SQ\", pow(col(\"MIN_YEARS_EXPERIENCE\"), 2))\n\n# Assemble polynomial features\nassembler_poly = VectorAssembler(\n    inputCols=[\n        \"MIN_YEARS_EXPERIENCE\", \"MIN_YEARS_EXPERIENCE_SQ\",\n        \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"\n    ] + [f\"{col}_vec\" for col in categorical_cols],\n    outputCol=\"features_poly\"\n)\n\nregression_data_poly_final=assembler_poly.transform(regression_data_poly)\n#show final structure\nregression_data_poly_final.select(\"SALARY\", \"features\", \"features_poly\").show(5, truncate=False)\n\n+------+-------------------------------+------------------------------------------+\n|SALARY|features                       |features_poly                             |\n+------+-------------------------------+------------------------------------------+\n|92962 |[2.0,18.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[2.0,4.0,18.0,1.0,1.0])   |\n|107645|(7,[0,1,2],[10.0,18.0,1.0])    |(10,[0,1,2,5],[10.0,100.0,18.0,1.0])      |\n|192800|[6.0,55.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[6.0,36.0,55.0,1.0,1.0])  |\n|125900|[12.0,18.0,1.0,0.0,1.0,0.0,0.0]|(10,[0,1,2,5,7],[12.0,144.0,18.0,1.0,1.0])|\n|170000|[6.0,18.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[6.0,36.0,18.0,1.0,1.0])  |\n+------+-------------------------------+------------------------------------------+\nonly showing top 5 rows"
  },
  {
    "objectID": "assignment04-juliocesarvg.html#generalized-linear-regression-summary",
    "href": "assignment04-juliocesarvg.html#generalized-linear-regression-summary",
    "title": "Assignment 04",
    "section": "4.1 4.1 Generalized Linear Regression Summary",
    "text": "4.1 4.1 Generalized Linear Regression Summary\n\nfrom pyspark.ml.regression import GeneralizedLinearRegression\n\nfeature_names = assembler.getInputCols()\n\nglr = GeneralizedLinearRegression(\n    featuresCol=\"features\",\n    labelCol=\"SALARY\",\n    family=\"gaussian\", \n    link=\"identity\", \n    maxIter=10, \n    regParam=0.3 \n)\n# Train the GLR model using the training dataset to learn the relationship between features and SALARY\nglr_model = glr.fit(regression_train)\nsummary = glr_model.summary\n\n# Coefficients and Intercept\nprint(\"Intercept: {:.4f}\".format(glr_model.intercept))\nprint(\"Coefficients:\")\nfor i, coef in enumerate(glr_model.coefficients):\n    print(f\" Feature {i + 1}: {coef:.4f}\")\n    \n# Summary stats\nprint(\"\\n--- Regression Summary ---\")\nprint(\"Coefficient Standard Errors:\", [f\"{val:.4f}\" for val in summary.coefficientStandardErrors])\nprint(\"T Values:\", [f\"{val:.4f}\" for val in summary.tValues])\nprint(\"P Values:\", [f\"{val:.4f}\" for val in summary.pValues])\n\n# print(f\"\\nDispersion: {summary.dispersion:.4f}\")\nprint(f\"Null Deviance: {summary.nullDeviance:.4f}\")\nprint(f\"Residual DF Null: {summary.residualDegreeOfFreedomNull}\")\nprint(f\"Deviance: {summary.deviance:.4f}\")\nprint(f\"Residual DF: {summary.residualDegreeOfFreedom}\")\nprint(f\"AIC: {summary.aic:.4f}\")\n\n# 1. Pull feature names directly from Java backend\nfeature_names = summary._call_java(\"featureNames\")\n\n# 2. Construct full table including intercept\nfeatures = [\"Intercept\"] + feature_names\ncoefs = [glr_model.intercept] + list(glr_model.coefficients)\nse = list(summary.coefficientStandardErrors)\ntvals = list(summary.tValues)\npvals = list(summary.pValues)\n\n#This block ensures all regression output values (coefficients, errors, t-values, p-values) \n\n# print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n# print(\"Length of features:\", len(features))\n# print(\"Length of coefs:\", len(coefs))\n# print(\"Length of se:\", len(se))\n# print(\"Length of tvals:\", len(tvals))\n# print(\"Length of pvals:\", len(pvals))\n\n\ncoef_table = pd.DataFrame({\n    \"Feature\": features,\n    \"Estimate\": [f\"{v:.4f}\" if v is not None else None for v in coefs],\n    \"Std Error\": [f\"{v:.4f}\" if v is not None else None for v in se],\n    \"t-stat\": [f\"{v:.4f}\" if v is not None else None for v in tvals],\n    \"p-Value\": [f\"{v:.4f}\" if v is not None else None for v in pvals]\n})\n\n\n# 4. Save for report\ncoef_table.to_csv(\"output/glr_summary.csv\", index=False)\n\n# 5. Optional pretty print\nHTML(coef_table.to_html())\n\n[Stage 51:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\nIntercept: 75142.6520\nCoefficients:\n Feature 1: 6629.0352\n Feature 2: -89.0893\n Feature 3: 758.1210\n Feature 4: -6686.4509\n Feature 5: 10858.3452\n Feature 6: 13681.8588\n Feature 7: 18835.8525\n\n--- Regression Summary ---\n\n\n[Stage 52:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\nCoefficient Standard Errors: ['81.3631', '23.5386', '2051.7917', '2611.3277', '2048.9189', '2105.9892', '2544.8043', '2786.7053']\nT Values: ['81.4747', '-3.7848', '0.3695', '-2.5606', '5.2995', '6.4966', '7.4017', '26.9647']\nP Values: ['0.0000', '0.0002', '0.7118', '0.0105', '0.0000', '0.0000', '0.0000', '0.0000']\n\n\n[Stage 55:&gt;                                                         (0 + 1) / 1]                                                                                \n\n\nNull Deviance: 35794690345776.1094\nResidual DF Null: 18965\nDeviance: 26380276237620.0078\nResidual DF: 18958\n\n\n[Stage 56:&gt;                                                         (0 + 1) / 1]\n\n\nAIC: 453136.8230\n\n\n                                                                                \n\n\n\n\n\n\nFeature\nEstimate\nStd Error\nt-stat\np-Value\n\n\n\n\n0\nIntercept\n75142.6520\n81.3631\n81.4747\n0.0000\n\n\n1\nMIN_YEARS_EXPERIENCE\n6629.0352\n23.5386\n-3.7848\n0.0002\n\n\n2\nDURATION\n-89.0893\n2051.7917\n0.3695\n0.7118\n\n\n3\nEMPLOYMENT_TYPE_NAME_vec_Fulltime\n758.1210\n2611.3277\n-2.5606\n0.0105\n\n\n4\nEMPLOYMENT_TYPE_NAME_vec_Parttime\n-6686.4509\n2048.9189\n5.2995\n0.0000\n\n\n5\nREMOTE_TYPE_NAME_vec_Undefined\n10858.3452\n2105.9892\n6.4966\n0.0000\n\n\n6\nREMOTE_TYPE_NAME_vec_Remote\n13681.8588\n2544.8043\n7.4017\n0.0000\n\n\n7\nREMOTE_TYPE_NAME_vec_Hybrid\n18835.8525\n2786.7053\n26.9647\n0.0000"
  },
  {
    "objectID": "assignment04-juliocesarvg.html#feature-importance-plot-6.1",
    "href": "assignment04-juliocesarvg.html#feature-importance-plot-6.1",
    "title": "Assignment 04",
    "section": "6.1 Feature Importance Plot 6.1",
    "text": "6.1 Feature Importance Plot 6.1\n\nExtract the feature importance from the Random Forest model and plot them using Seaborn.\nUse a bar plot to visualize the top 10 most important features.\nSave the plot as rf_feature_importance.png in the _output/ folder.\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\n# feature importances\nimportances = rf_model.featureImportances.toArray()\n\n# nombres reales (expandido, incluyendo OHE) desde el metadata\nmeta = regression_data_rf.schema[\"features_rf\"].metadata\nattrs = []\nfor k in [\"numeric\", \"binary\"]:\n    if k in meta.get(\"ml_attr\", {}).get(\"attrs\", {}):\n        attrs += meta[\"ml_attr\"][\"attrs\"][k]\nfeature_names = [a[\"name\"] for a in sorted(attrs, key=lambda x: x[\"idx\"])]\n\nprint(importances)\nprint(feature_names)\nprint(assembler_rf.getInputCols())\n\n# to DataFrame\nfi_df = pd.DataFrame({\n    \"Feature\": feature_names,\n    \"Importance\": importances\n}).sort_values(by=\"Importance\", ascending=False)\n\ntop10 = fi_df.head(10)\n\n\n# plot\nsns.barplot(x=\"Importance\", y=\"Feature\", data=top10)\nplt.title(\"Top 10 Feature Importances (Random Forest)\")\nplt.savefig(\"output/rf_feature_importance.png\", dpi=300, bbox_inches=\"tight\")\nplt.show()\n\n[0.87986289 0.06420253 0.01016472 0.00886554 0.01079688 0.01421165\n 0.01189578]\n['MIN_YEARS_EXPERIENCE', 'DURATION', 'EMPLOYMENT_TYPE_NAME_vec_Fulltime', 'EMPLOYMENT_TYPE_NAME_vec_Parttime', 'REMOTE_TYPE_NAME_vec_Undefined', 'REMOTE_TYPE_NAME_vec_Remote', 'REMOTE_TYPE_NAME_vec_Hybrid']\n['MIN_YEARS_EXPERIENCE', 'DURATION', 'EMPLOYMENT_TYPE_NAME_vec', 'REMOTE_TYPE_NAME_vec']"
  },
  {
    "objectID": "assignment04-juliocesarvg.html#comments-7.1",
    "href": "assignment04-juliocesarvg.html#comments-7.1",
    "title": "Assignment 04",
    "section": "7.1 Comments (7.1)",
    "text": "7.1 Comments (7.1)\n\nThe Random Forest model has the lowest RMSE, so it predicts better than the other two models.\nAll models show that when the real salary goes up, the predicted one also goes up.\nSome strange points may happen because the models are not perfect and have small inaccuracies, or because some factors that affect salary are not in the data."
  },
  {
    "objectID": "assignment04-juliocesarvg.html#calculating-log-likelihood-and-bic-for-pyspark-models-7.2",
    "href": "assignment04-juliocesarvg.html#calculating-log-likelihood-and-bic-for-pyspark-models-7.2",
    "title": "Assignment 04",
    "section": "7.2 Calculating Log-Likelihood and BIC for PySpark Models (7.2)",
    "text": "7.2 Calculating Log-Likelihood and BIC for PySpark Models (7.2)\nLog Likelihood represents the probability of observing the data given the model parameters. It is used in AIC and BIC calculations. Log Likelihood is not directly available in PySparkâ€™s GeneralizedLinearRegression model summary. However, you can calculate it using the deviance and the number of observations.\n\nimport numpy as np\n\n\n# Procedure with parameters to calculate Log-Likelihood and BIC\ndef calc_loglik_bic(model):\n    s = model.summary\n    n = s.numInstances          # number of observations\n    k = len(model.coefficients) + 1\n    dev = s.deviance\n    disp = s.dispersion\n\n    Log_Likelihood = -0.5 * (n * np.log(2 * np.pi) + n * np.log(disp) + dev / disp)\n    bic = k * np.log(n) - 2 * Log_Likelihood\n    return Log_Likelihood, bic\n\n# Calculate for GLR and Polynomial GLR with procedure and input parameters\nloglik_glr,  bic_glr  = calc_loglik_bic(glr_model)\nloglik_poly, bic_poly = calc_loglik_bic(poly_glr_min_years_model)\n\nprint(f\"GLR -&gt; Log-Likelihood: {loglik_glr:.2f},  BIC: {bic_glr:.2f}\")\nprint(f\"Polynomial GLR -&gt; Log-Likelihood: {loglik_poly:.2f},  BIC: {bic_poly:.2f}\")\n\nGLR -&gt; Log-Likelihood: -226559.41,  BIC: 453197.63\nPolynomial GLR -&gt; Log-Likelihood: -226314.10,  BIC: 452736.56"
  },
  {
    "objectID": "assignment04-juliocesarvg.html#comments",
    "href": "assignment04-juliocesarvg.html#comments",
    "title": "Assignment 04",
    "section": "7.3 Comments",
    "text": "7.3 Comments\n\nThe Polynomial GLR fits the data slightly better since it has a lower BIC value but both models perform almost equally well.\nOverall, both GLR models provide a good fitbut the Polynomial GLR show a slightly better performance based on its lower BIC value."
  }
]